{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJSxR-Hvm2DH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjzTDLNPm5Gi"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "file_path = \"/content/balanced_k8s_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df_cleaned = df.drop(columns=['node_status', 'pod_state'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMj4IsoKnLAa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split features and target\n",
        "X = df_cleaned.drop(columns=['failure_type'])\n",
        "y = df_cleaned['failure_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsfocrxinP_p"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6aRHb8BnUbN"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iLtWgvGnYdT"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class K8sFailureMLP(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(K8sFailureMLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 128)\n",
        "    self.bn1 = nn.BatchNorm1d(128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.bn2 = nn.BatchNorm1d(64)\n",
        "    self.fc3 = nn.Linear(64, 32)\n",
        "    self.bn3 = nn.BatchNorm1d(32)\n",
        "    self.output = nn.Linear(32, num_classes)\n",
        "    self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "    return self.output(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4d0gZLcnccu"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "num_classes = len(torch.unique(y_tensor))\n",
        "model = K8sFailureMLP(input_size=X_train.shape[1], num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgWWUvRtnhF6",
        "outputId": "f78750bd-0702-4490-c5bb-2991c0d4cef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.5183\n",
            "Epoch 2/20, Loss: 0.4162\n",
            "Epoch 3/20, Loss: 0.4059\n",
            "Epoch 4/20, Loss: 0.3979\n",
            "Epoch 5/20, Loss: 0.3918\n",
            "Epoch 6/20, Loss: 0.3910\n",
            "Epoch 7/20, Loss: 0.3866\n",
            "Epoch 8/20, Loss: 0.3841\n",
            "Epoch 9/20, Loss: 0.3867\n",
            "Epoch 10/20, Loss: 0.3814\n",
            "Epoch 11/20, Loss: 0.3742\n",
            "Epoch 12/20, Loss: 0.3797\n",
            "Epoch 13/20, Loss: 0.3774\n",
            "Epoch 14/20, Loss: 0.3777\n",
            "Epoch 15/20, Loss: 0.3719\n",
            "Epoch 16/20, Loss: 0.3742\n",
            "Epoch 17/20, Loss: 0.3722\n",
            "Epoch 18/20, Loss: 0.3682\n",
            "Epoch 19/20, Loss: 0.3681\n",
            "Epoch 20/20, Loss: 0.3717\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PfZArupnlpR",
        "outputId": "81ea6aa3-5872-4c58-aecb-2da719854cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7776\n",
            "Precision: 0.7831\n",
            "Recall: 0.7776\n",
            "F1 Score: 0.7456\n",
            "Confusion Matrix:\n",
            "[[997   0   1   2   0]\n",
            " [  0 864  25 109   2]\n",
            " [  0  78 914   6   2]\n",
            " [  0 862  24 114   0]\n",
            " [  0   0   1   0 999]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1000\n",
            "           1       0.48      0.86      0.62      1000\n",
            "           2       0.95      0.91      0.93      1000\n",
            "           3       0.49      0.11      0.19      1000\n",
            "           4       1.00      1.00      1.00      1000\n",
            "\n",
            "    accuracy                           0.78      5000\n",
            "   macro avg       0.78      0.78      0.75      5000\n",
            "weighted avg       0.78      0.78      0.75      5000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(batch_y.numpy())\n",
        "        y_pred.extend(predicted.numpy())\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "class_report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcQguJBVn0s6",
        "outputId": "b7ab1eab-656a-4f54-f672-b5798ac94aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Failure Type: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Testing with new data\n",
        "def predict(model, scaler, new_data):\n",
        "    model.eval()\n",
        "    new_data_scaled = scaler.transform(new_data)\n",
        "    new_tensor = torch.tensor(new_data_scaled, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(new_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.numpy()\n",
        "\n",
        "new_sample = np.array([X.iloc[0].values])\n",
        "predicted_class = predict(model, scaler, new_sample)\n",
        "print(f\"Predicted Failure Type: {predicted_class[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p73tsAaKn4ia"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
